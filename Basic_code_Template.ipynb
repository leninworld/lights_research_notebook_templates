{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJHA2u5Ss7DZag/G7C5mVR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Basic code snippets and workflow\n"
      ],
      "metadata": {
        "id": "OcxgYL4mE3ZK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7hjwAAsE1AF"
      },
      "outputs": [],
      "source": [
        "#Mounting colab and drive\n",
        "\n",
        "from google.colab import drive\n",
        "#Note: this will pop up asking for google login permission\n",
        "drive.mount('/content/drive')\n",
        "#linux command to list the files under linux running\n",
        "#Colab Jupyter notebook (Prints dir/files/links in your Drive)\n",
        "!ls -ltr /content/drive/MyDrive/ | grep *.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for specific data from drive\n",
        "\n",
        "!ls -ltr /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "WZD6VPYKcCYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing required library\n",
        "\n",
        "import warnings\n",
        "import traceback\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from tabulate import tabulate\n",
        "from sklearn import naive_bayes\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.utils import class_weight\n",
        "warnings.filterwarnings(action='ignore')\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics  import f1_score,accuracy_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "fzXL2J4PcQM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating pretty print function\n",
        "\n",
        "n=2\n",
        "def pretty_print(df,n)\n",
        "print(tabulate(df.head(n), headers='keys', tablefmt='psql'))"
      ],
      "metadata": {
        "id": "yuW9W71ynZ6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading dataset from drive\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/')\n",
        "pretty_print(df,1)\n",
        "\n",
        "#CHeck the size and shape of the dataset\n",
        "print('Shape', df.shape)\n",
        "print('Size', df.size)"
      ],
      "metadata": {
        "id": "0NJAiXFM5CqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the data types and info of the data\n",
        "df.info()\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "jFL5IdEGrwC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data statistics\n",
        "\n",
        "df.describe().T"
      ],
      "metadata": {
        "id": "COAcHNMD8ba1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop columns\n",
        "\n",
        "df = df.drop(columns=['Column1', 'Column2','Column3','Column4'])\n",
        "pretty_print(df1,1)\n",
        "print(\"Shape:\", df.shape)"
      ],
      "metadata": {
        "id": "kSN2Q77_tt7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Preprocessing\n",
        "\n",
        "#Text data included with the numeric data(Counties). So we need to encode that in some numeric form before splitting the train test data\n",
        "\n",
        "df_new = df.copy()\n",
        "pretty_print(df,1)"
      ],
      "metadata": {
        "id": "GntHhjz99H2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordinalencoding on multiple columns conversion of categorical to numeric values without labels\n",
        "\n",
        "enc = OrdinalEncoder()\n",
        "enc.fit(df_explode_countyids[[\"Col4\",\"Col5\", \"Col6\"]])\n",
        "df_explode_countyids[[\"Col4\",\"Col5\", \"Col6\"]] = enc.transform(df_explode_countyids[[\"Col4\",\"Col5\", \"Col6\"]])\n",
        "pretty_print(df_explode_countyids, 10)"
      ],
      "metadata": {
        "id": "qgESVOKq9d90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Label Encoding , is used only once on single column of dataframe, to use particular column as label.\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "df_new ['LabelCol'] = label_encoder.fit_transform(df_explode_countyids['LabelCol'])\n",
        "pretty_print(df_new,2)"
      ],
      "metadata": {
        "id": "y4Wy1ZmE9k1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating def function\n",
        "\n",
        "def convert_list(row):\n",
        "  mList = [int(e) if e.isdigit() else e for e in str(row['Ids']).split(',')]\n",
        "  return mList\n",
        "\n",
        "#Create new column to store value to str or int by passing function on dataframe\n",
        "df_new['Ids_new'] = df_new.apply(convert_list, axis=1)\n",
        "df_new = df_new.explode('Ids_new')\n",
        "#pretty_print(df_explode_countyids,2)\n",
        "df_new.dtypes"
      ],
      "metadata": {
        "id": "eBwy182g9uUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating def function for changing the dtype of object to numeric dtype\n",
        "\n",
        "ef fill_na_0(row):\n",
        "  if str(row['Ids_new']).isnumeric():\n",
        "   return int(row['Ids_new'])\n",
        "  else:\n",
        "   return 0\n",
        "#Creating new column\n",
        "df_new['new_Ids'] = df_new.apply(fill_na_0, axis=1)\n",
        "pretty_print(df_new,1)\n",
        "df_new.dtypes"
      ],
      "metadata": {
        "id": "lw8RVxzV-Qdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping non-numeric data type columns\n",
        "\n",
        "df_new = df_new.drop(columns=['Ids','Ids_new'])\n",
        "# pretty_print(df_explode_countyids,2)\n",
        "df_new.dtypes"
      ],
      "metadata": {
        "id": "_jJ3Sk6n-crd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#created new function for lambda for label column\n",
        "m = df_new['LabelCol'].mean()\n",
        "print(\"mean\",m)\n",
        "\n",
        "sd = df_new['LabelCol'].std()\n",
        "print(\"standard deviation\",sd)\n",
        "\n",
        "def lambda_dup(df_new):\n",
        "  if (df_new['LabelCol'] == 0):\n",
        "        return 0\n",
        "  elif (df_new['LabelCol'] <= m + 1*sd):\n",
        "        return 1\n",
        "  elif (df_new['LabelCol'] <= m+ 2*sd):\n",
        "        return 2\n",
        "  elif (df_new['LabelCol'] <= m + 3*sd):\n",
        "        return 3\n",
        "  else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "1qkMy-d6AeCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying lambda function on dataframe & creating new column named lambda_dup_num\n",
        "\n",
        "df_new['lambda_dup_num'] = df_new.apply(lambda_dup, axis=1)\n",
        "pretty_print(df_new,1)\n",
        "df_new.dtypes"
      ],
      "metadata": {
        "id": "cxcbyvOsAxSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying lambda function on new column\n",
        "\n",
        "def ordinal_encoding(df_new,column,ordering):\n",
        "  df_new = df_new.copy()\n",
        "  df_new[column] = df_new[column].apply(lambda_dup)\n",
        "  return df_new"
      ],
      "metadata": {
        "id": "di3LlcKIBotI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def function for choosing classification or regression\n",
        "\n",
        "ef preprocessing(df_new,task):\n",
        "  df_new=df_new.copy()\n",
        "\n",
        "  if task=='Regression':\n",
        "    Y=df_new['lambda_dup_num']\n",
        "  elif task=='Classification':\n",
        "    Y=df_new['lambda_dup_num']\n",
        "\n",
        "  X=df_new.drop(['lambda_dup_num','AcresBurned'],axis=1)\n",
        "\n",
        "  X_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size=0.65,shuffle=True,random_state=1)\n",
        "\n",
        "  scaler=StandardScaler()\n",
        "  scaler.fit(X_train)\n",
        "\n",
        "  X_train=pd.DataFrame(scaler.transform(X_train),columns=X.columns)\n",
        "  X_test=pd.DataFrame(scaler.transform(X_test),columns=X.columns)\n",
        "  return X_train,X_test,Y_train,Y_test"
      ],
      "metadata": {
        "id": "sDLNX83hD509"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Before passing data to model create test and train data points\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = preprocessing(df_explode_countyids, task='Classification')\n",
        "X_train.head(1)\n",
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "metadata": {
        "id": "Sm0He48uCK4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CHecking values\n",
        "\n",
        "df_new[\"lambda_dup_num\"].value_counts()"
      ],
      "metadata": {
        "id": "IPczJ13ky3lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving dataframe to new variable\n",
        "\n",
        "dfc = df_new.copy()\n",
        "#print(dfc)"
      ],
      "metadata": {
        "id": "W3-cbYq3zbZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting Machine Learning Algorithm (Support Vector Machine Classifiers)\n",
        "\n",
        "svm = SVC(C=0.2, kernel='linear', gamma='auto', class_weight='balanced', max_iter=1000)\n",
        "svm.fit(X_train, Y_train)\n",
        "Y_pred = svm.predict(X_test)\n",
        "print(cross_validate(svm, X_train, Y_train, cv=10))\n",
        "print(classification_report(Y_test, Y_pred, labels=[0,1,2,3], target_names=[\"no_fire\", \"low_fire\", \"moderate_fire\",\"high_fire\"]))\n",
        "print(metrics.balanced_accuracy_score(Y_test, Y_pred))\n",
        "print(\"Test run 1\")\n",
        "print(\"The C value is 0.2 and max_iter is 1000\")"
      ],
      "metadata": {
        "id": "416j89C5zt8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zQ8YFM8H0KYK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}