{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leninworld/lights_research_notebook_templates/blob/main/machine_learning_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Basic code snippets and workflow\n"
      ],
      "metadata": {
        "id": "OcxgYL4mE3ZK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7hjwAAsE1AF"
      },
      "outputs": [],
      "source": [
        "# mounting colab and drive\n",
        "from google.colab import drive\n",
        "# Note: this will pop up asking for google login permission\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# linux command to list the files under linux running with ! at the start of the command\n",
        "# colab Jupyter notebook (Prints dir/files/links in your Drive)\n",
        "!ls -ltr /content/drive/MyDrive/ | grep *.csv"
      ],
      "metadata": {
        "id": "DiUHAY_tHlsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check for specific data from drive\n",
        "!ls -ltr /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "WZD6VPYKcCYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing required library\n",
        "\n",
        "import warnings\n",
        "import traceback\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from tabulate import tabulate\n",
        "from sklearn import naive_bayes\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.utils import class_weight\n",
        "warnings.filterwarnings(action='ignore')\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics  import f1_score,accuracy_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "fzXL2J4PcQM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating pretty print function\n",
        "\n",
        "n=2\n",
        "def pretty_print(df,n)\n",
        "print(tabulate(df.head(n), headers='keys', tablefmt='psql'))"
      ],
      "metadata": {
        "id": "yuW9W71ynZ6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading dataset from drive\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/')\n",
        "pretty_print(df,1)\n",
        "\n",
        "# check the size and shape of the dataset\n",
        "print('Shape', df.shape)\n",
        "print('Size', df.size)"
      ],
      "metadata": {
        "id": "0NJAiXFM5CqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the data types and info of the data\n",
        "df.info()\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "jFL5IdEGrwC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data statistics\n",
        "\n",
        "df.describe().T"
      ],
      "metadata": {
        "id": "COAcHNMD8ba1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop columns\n",
        "\n",
        "df = df.drop(columns=['Column1', 'Column2','Column3','Column4'])\n",
        "pretty_print(df1,1)\n",
        "print(\"Shape:\", df.shape)"
      ],
      "metadata": {
        "id": "kSN2Q77_tt7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data Preprocessing\n",
        "\n",
        "# text data included with the numeric data(Counties).\n",
        "# So we need to encode that in some numeric form before splitting the train test data\n",
        "\n",
        "df_new = df.copy()\n",
        "pretty_print(df,1)"
      ],
      "metadata": {
        "id": "GntHhjz99H2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordinalencoding on multiple columns conversion of categorical to numeric values without labels\n",
        "\n",
        "enc = OrdinalEncoder()\n",
        "enc.fit(df_explode_countyids[[\"Col4\",\"Col5\", \"Col6\"]])\n",
        "df_explode_countyids[[\"Col4\",\"Col5\", \"Col6\"]] = enc.transform(df_explode_countyids[[\"Col4\",\"Col5\", \"Col6\"]])\n",
        "pretty_print(df_explode_countyids, 10)"
      ],
      "metadata": {
        "id": "qgESVOKq9d90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LabelEncoding , is used only once on single column of dataframe, to use particular column as label.\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "df_new ['<label>'] = label_encoder.fit_transform(df_explode_countyids['<label>'])\n",
        "pretty_print(df_new,2)"
      ],
      "metadata": {
        "id": "y4Wy1ZmE9k1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function - convert to list having only numbers\n",
        "\n",
        "def convert_list(row):\n",
        "  mList = [int(e) if e.isdigit() else e for e in str(row['Ids']).split(',')]\n",
        "  return mList\n",
        "\n",
        "# create new column to store value to str or int by passing function on dataframe\n",
        "df_new['Ids_new'] = df_new.apply(convert_list, axis=1)\n",
        "df_new = df_new.explode('Ids_new')\n",
        "#pretty_print(df_explode_countyids, 2)\n",
        "df_new.dtypes"
      ],
      "metadata": {
        "id": "eBwy182g9uUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function - function for changing the dtype of object to numeric dtype\n",
        "\n",
        "def fill_na_0(row):\n",
        "  if str(row['Ids_new']).isnumeric():\n",
        "   return int(row['Ids_new'])\n",
        "  else:\n",
        "   return 0\n",
        "\n",
        "# creating new column\n",
        "df_new['new_Ids'] = df_new.apply(fill_na_0, axis=1)\n",
        "pretty_print(df_new,1)\n",
        "df_new.dtypes"
      ],
      "metadata": {
        "id": "lw8RVxzV-Qdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping non-numeric data type columns\n",
        "\n",
        "df_new = df_new.drop(columns=['Ids','Ids_new'])\n",
        "# pretty_print(df_explode_countyids,2)\n",
        "df_new.dtypes"
      ],
      "metadata": {
        "id": "_jJ3Sk6n-crd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# created new function for lambda for label column\n",
        "m = df_new['<label>'].mean()\n",
        "print(\"mean\",m)\n",
        "\n",
        "sd = df_new['<label>'].std()\n",
        "print(\"standard deviation\",sd)\n",
        "\n",
        "def lambda_dup(df_new):\n",
        "  if (df_new['<label>'] == 0):\n",
        "        return 0\n",
        "  elif (df_new['<label>'] <= m + 1*sd):\n",
        "        return 1\n",
        "  elif (df_new['<label>'] <= m+ 2*sd):\n",
        "        return 2\n",
        "  elif (df_new['<label>'] <= m + 3*sd):\n",
        "        return 3\n",
        "  else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "1qkMy-d6AeCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying lambda function on dataframe & creating new column named lambda_dup_num\n",
        "\n",
        "df_new['lambda_dup_num'] = df_new.apply(lambda_dup, axis=1)\n",
        "pretty_print(df_new,1)\n",
        "df_new.dtypes"
      ],
      "metadata": {
        "id": "cxcbyvOsAxSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying lambda function on new column\n",
        "\n",
        "def ordinal_encoding(df_new,column,ordering):\n",
        "  df_new = df_new.copy()\n",
        "  df_new[column] = df_new[column].apply(lambda_dup)\n",
        "  return df_new"
      ],
      "metadata": {
        "id": "di3LlcKIBotI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for classification or regression\n",
        "\n",
        "def preprocessing(df_new,task):\n",
        "  df_new=df_new.copy()\n",
        "\n",
        "  if task=='Regression':\n",
        "    Y=df_new['lambda_dup_num'] # label/target\n",
        "  elif task=='Classification':\n",
        "    Y=df_new['lambda_dup_num'] # label/target\n",
        "\n",
        "  # drop columns having label/target\n",
        "  X=df_new.drop(['lambda_dup_num','AcresBurned'],axis=1)\n",
        "\n",
        "  # train-test set splitting\n",
        "  X_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size=0.65,shuffle=True,random_state=1)\n",
        "\n",
        "  # apply standard scalar on training set\n",
        "  scaler=StandardScaler()\n",
        "  scaler.fit(X_train)\n",
        "  # standard scalar transformation\n",
        "  X_train=pd.DataFrame(scaler.transform(X_train),columns=X.columns)\n",
        "  X_test=pd.DataFrame(scaler.transform(X_test),columns=X.columns)\n",
        "  return X_train,X_test,Y_train,Y_test"
      ],
      "metadata": {
        "id": "sDLNX83hD509"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# before passing data to model create test and train data points\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = preprocessing(df_explode_countyids, task='Classification')\n",
        "X_train.head(1)\n",
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "metadata": {
        "id": "Sm0He48uCK4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking values\n",
        "df_new[\"lambda_dup_num\"].value_counts()"
      ],
      "metadata": {
        "id": "IPczJ13ky3lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving dataframe to new variable\n",
        "dfc = df_new.copy()\n",
        "#print(dfc)"
      ],
      "metadata": {
        "id": "W3-cbYq3zbZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Classification Code (boilerplate)"
      ],
      "metadata": {
        "id": "lNNXhGLiR26k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression Classifier\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, balanced_accuracy_score, cross_validate\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "log_reg_model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
        "\n",
        "# Train the model\n",
        "log_reg_model.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions\n",
        "Y_pred_log_reg = log_reg_model.predict(X_test)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_results = cross_validate(log_reg_model, X_train, Y_train, cv=10)\n",
        "print(\"Logistic Regression Cross-Validation Results:\", cv_results)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(Y_test, Y_pred_log_reg, labels=[0, 1, 2, 3], target_names=[\"no_fire\", \"low_fire\", \"moderate_fire\", \"high_fire\"]))\n",
        "\n",
        "# Print balanced accuracy score\n",
        "print(\"Logistic Regression Balanced Accuracy Score:\", balanced_accuracy_score(Y_test, Y_pred_log_reg))\n",
        "\n",
        "print(\"Test run 1\")\n"
      ],
      "metadata": {
        "id": "I0x0jt1gQHjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Machine Learning Algorithm  => Support Vector Machine Classifiers\n",
        "\n",
        "svm = SVC(C=0.2, kernel='linear', gamma='auto', class_weight='balanced', max_iter=1000)\n",
        "svm.fit(X_train, Y_train)\n",
        "Y_pred = svm.predict(X_test)\n",
        "print(cross_validate(svm, X_train, Y_train, cv=10))\n",
        "print(classification_report(Y_test, Y_pred, labels=[0,1,2,3], target_names=[\"no_fire\", \"low_fire\", \"moderate_fire\",\"high_fire\"]))\n",
        "print(metrics.balanced_accuracy_score(Y_test, Y_pred))\n",
        "print(\"Test run 1\")\n",
        "print(\"The C value is 0.2 and max_iter is 1000\")"
      ],
      "metadata": {
        "id": "416j89C5zt8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Machine Learning Algorithm  => Naive Bayes model Classifiers\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report, balanced_accuracy_score, cross_validate\n",
        "\n",
        "# Initialize the Naive Bayes model\n",
        "nb_model = GaussianNB()\n",
        "\n",
        "# Train the model\n",
        "nb_model.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions\n",
        "Y_pred_nb = nb_model.predict(X_test)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_results = cross_validate(nb_model, X_train, Y_train, cv=10)\n",
        "print(\"Naive Bayes Cross-Validation Results:\", cv_results)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(Y_test, Y_pred_nb, labels=[0, 1, 2, 3], target_names=[\"no_fire\", \"low_fire\", \"moderate_fire\", \"high_fire\"]))\n",
        "\n",
        "# Print balanced accuracy score\n",
        "print(\"Naive Bayes Balanced Accuracy Score:\", balanced_accuracy_score(Y_test, Y_pred_nb))\n",
        "\n",
        "print(\"Test run 1\")\n"
      ],
      "metadata": {
        "id": "mQxYqkyHO2iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Machine Learning Algorithm  => Random Forest model Classifiers\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, balanced_accuracy_score, cross_validate\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions\n",
        "Y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_results = cross_validate(rf_model, X_train, Y_train, cv=10)\n",
        "print(\"Random Forest Cross-Validation Results:\", cv_results)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(Y_test, Y_pred_rf, labels=[0, 1, 2, 3], target_names=[\"no_fire\", \"low_fire\", \"moderate_fire\", \"high_fire\"]))\n",
        "\n",
        "# Print balanced accuracy score\n",
        "print(\"Random Forest Balanced Accuracy Score:\", balanced_accuracy_score(Y_test, Y_pred_rf))\n",
        "\n",
        "print(\"Test run 1\")\n"
      ],
      "metadata": {
        "id": "k2R0bNgxQL40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Machine Learning Algorithm  => Multi Layer Perceptron (MLP) Classifer\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, balanced_accuracy_score, cross_validate\n",
        "\n",
        "# Initialize the MLP model\n",
        "mlp_model = MLPClassifier(max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "mlp_model.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions\n",
        "Y_pred_mlp = mlp_model.predict(X_test)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_results = cross_validate(mlp_model, X_train, Y_train, cv=10)\n",
        "print(\"MLP Cross-Validation Results:\", cv_results)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(Y_test, Y_pred_mlp, labels=[0, 1, 2, 3], target_names=[\"no_fire\", \"low_fire\", \"moderate_fire\", \"high_fire\"]))\n",
        "\n",
        "# Print balanced accuracy score\n",
        "print(\"MLP Balanced Accuracy Score:\", balanced_accuracy_score(Y_test, Y_pred_mlp))\n",
        "\n",
        "print(\"Test run 1\")"
      ],
      "metadata": {
        "id": "FF1y36OZQRpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression code (boilerplate)"
      ],
      "metadata": {
        "id": "k637xBm9-RmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read data and perform train-test split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Load your dataset\n",
        "# Replace 'your_dataset.csv' with the path to your dataset file\n",
        "data = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Assuming your dataset has features (X) and target variable (y)\n",
        "X = data.drop(columns=['target_column'])  # replace 'target_column' with the name of your target variable\n",
        "y = data['target_column']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zQ8YFM8H0KYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best alpha for Ridge Regression\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge = Ridge()   # HT for Ridge\n",
        "param_grid_ridge = {'alpha': [0.1, 1, 10]}\n",
        "ridge_cv = GridSearchCV(estimator=ridge, param_grid=param_grid_ridge, scoring='neg_mean_squared_error', cv=5)\n",
        "ridge_cv.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best alpha for Ridge Regression:\", ridge_cv.best_params_)"
      ],
      "metadata": {
        "id": "x1Vboo3CSe8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Linear Regression"
      ],
      "metadata": {
        "id": "G4qa5DmdTTie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression Model\n",
        "\n",
        "# Initialize the linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Calculate R² Score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R² Score:\", r2)"
      ],
      "metadata": {
        "id": "UhmWZ8RfBNo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Support Vector Regression (SVR)"
      ],
      "metadata": {
        "id": "2B23YCu5S4QW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Best C for Support Vector Regression (SVR) model\n",
        "svr = SVR(kernel='linear')   #HT for SVR\n",
        "param_grid_svr = {'C': [0.1, 1, 10]}\n",
        "svr_cv = GridSearchCV(estimator=svr, param_grid=param_grid_svr, scoring='neg_mean_squared_error', cv=5)\n",
        "svr_cv.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best C for SVR:\", svr_cv.best_params_)"
      ],
      "metadata": {
        "id": "ohWwAW5WSygH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Regression (SVR) model\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the SVR model\n",
        "svr_model = SVR()\n",
        "\n",
        "# Train the model\n",
        "svr_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_svr = svr_model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
        "print(\"SVR - Mean Squared Error:\", mse_svr)\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE)\n",
        "rmse_svr = np.sqrt(mse_svr)\n",
        "print(\"SVR - Root Mean Squared Error:\", rmse_svr)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae_svr = mean_absolute_error(y_test, y_pred_svr)\n",
        "print(\"SVR - Mean Absolute Error:\", mae_svr)\n",
        "\n",
        "# Calculate R² Score\n",
        "r2_svr = r2_score(y_test, y_pred_svr)\n",
        "print(\"SVR - R² Score:\", r2_svr)"
      ],
      "metadata": {
        "id": "QhHS-FpqOF62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Forest Regression"
      ],
      "metadata": {
        "id": "ksmSSRmMTdmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Regression\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_model = RandomForestRegressor()\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "print(\"Random Forest - Mean Squared Error:\", mse_rf)\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE)\n",
        "rmse_rf = np.sqrt(mse_rf)\n",
        "print(\"Random Forest - Root Mean Squared Error:\", rmse_rf)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
        "print(\"Random Forest - Mean Absolute Error:\", mae_rf)\n",
        "\n",
        "# Calculate R² Score\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "print(\"Random Forest - R² Score:\", r2_rf)"
      ],
      "metadata": {
        "id": "PxtSnkPMOMPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multi Layer Perceptron (MLP) Regression"
      ],
      "metadata": {
        "id": "EudKXo83TfTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi Layer Perceptron Regression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the MLP model\n",
        "mlp_model = MLPRegressor(max_iter=500)\n",
        "\n",
        "# Train the model\n",
        "mlp_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_mlp = mlp_model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
        "print(\"MLP - Mean Squared Error:\", mse_mlp)\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE)\n",
        "rmse_mlp = np.sqrt(mse_mlp)\n",
        "print(\"MLP - Root Mean Squared Error:\", rmse_mlp)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae_mlp = mean_absolute_error(y_test, y_pred_mlp)\n",
        "print(\"MLP - Mean Absolute Error:\", mae_mlp)\n",
        "\n",
        "# Calculate R² Score\n",
        "r2_mlp = r2_score(y_test, y_pred_mlp)\n",
        "print(\"MLP - R² Score:\", r2_mlp)"
      ],
      "metadata": {
        "id": "PolRc_FHOQVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi Layer Perceptron (MLP) Regressor with hyper parameter tuning\n",
        "\n",
        "\n",
        "mlp = MLPRegressor()\n",
        "\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "    'learning_rate': ['constant', 'adaptive']\n",
        "}\n",
        "\n",
        "\n",
        "mlp_cv = GridSearchCV(estimator=mlp, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
        "mlp_cv.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_params = mlp_cv.best_params_\n",
        "best_model = mlp_cv.best_estimator_\n",
        "print(\"Best parameters for MLPRegressor:\", best_params)\n",
        "\n",
        "\n",
        "# Prediction\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"MLPRegressor MSE on test set:\", mse)"
      ],
      "metadata": {
        "id": "hqAui3lrUFG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### K Nearest Neighbor Regressor"
      ],
      "metadata": {
        "id": "cpHcq6VpTqXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid Search for K Nearest Neighbor Regressor\n",
        "\n",
        "knn = KNeighborsRegressor()\n",
        "\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "\n",
        "knn_cv = GridSearchCV(estimator=knn, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
        "knn_cv.fit(X_train, y_train)\n",
        "\n",
        "best_params = knn_cv.best_params_\n",
        "best_model = knn_cv.best_estimator_\n",
        "print(\"Best parameters for KNeighborsRegressor:\", best_params)\n",
        "\n",
        "# Prediction\n",
        "y_pred = best_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"KNeighborsRegressor MSE on test set:\", mse)"
      ],
      "metadata": {
        "id": "cb4Gwi9GTto9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### XGBoost"
      ],
      "metadata": {
        "id": "7kl6RqvLVcmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost with hyper parameter tuning\n",
        "\n",
        "xgb_reg = xgb.XGBRegressor()\n",
        "\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.1, 0.3],\n",
        "    'n_estimators': [100, 500, 1000],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'alpha': [0, 0.1, 1],\n",
        "    'lambda': [0, 0.1, 1]\n",
        "}\n",
        "\n",
        "\n",
        "xgb_cv = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
        "xgb_cv.fit(X_train, y_train)\n",
        "\n",
        "best_params = xgb_cv.best_params_\n",
        "best_model = xgb_cv.best_estimator_\n",
        "print(\"Best parameters for XGBoost:\", best_params)\n",
        "\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"XGBoost MSE on test set:\", mse)\n"
      ],
      "metadata": {
        "id": "Oxa91bxNJwaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decision Tree Regressor"
      ],
      "metadata": {
        "id": "_iGtAaeHVXVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree Regressor\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_model = DecisionTreeRegressor(random_state=42)\n",
        "tree_model.fit(X_train, y_train)\n",
        "y_pred = tree_model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "print(\"R-squared (R2) Score:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "3k5gnTvpVE2e",
        "outputId": "383a5d80-b294-4c0e-bb67-a9c362c3de2a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-17131fe0fbec>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtree_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtree_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    }
  ]
}